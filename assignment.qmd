---
title: "Your title here"
date: "`r Sys.Date()`"
author: "530473439"
format: 
  html: 
    embed-resources: true # Creates a single HTML file as output
    code-fold: true # Code folding; allows you to show/hide code chunks
    code-tools: true # Includes a menu to download the code file 
    # code-tools are particularly important if you use inline R to 
    # improve the reproducibility of your report
table-of-contents: true # (Optional) Creates a table of contents
number-sections: true # (Optional) Puts numbers next to heading/subheadings
---

Trying to analyse traits of HD students

```{r}
library(tidyverse)
library(janitor)
library(hms)
library(patchwork)
library(ggpubr)
```

```{r}

x = readxl::read_excel("data/DATA2x02_survey_2024_Responses.xlsx")
old_names = colnames(x)
new_names = c(
  "timestamp",
  "target_grade",
  "assignment_preference",
  "trimester_or_semester",
  "age",
  "tendency_yes_or_no",
  "pay_rent",
  "urinal_choice",
  "stall_choice",
  "weetbix_count",
  "weekly_food_spend",
  "living_arrangements",
  "weekly_alcohol",
  "believe_in_aliens",
  "height",
  "commute",
  "daily_anxiety_frequency",
  "weekly_study_hours",
  "work_status",
  "social_media",
  "gender",
  "average_daily_sleep",
  "usual_bedtime",
  "sleep_schedule",
  "sibling_count",
  "allergy_count",
  "diet_style",
  "random_number",
  "favourite_number",
  "favourite_letter",
  "drivers_license",
  "relationship_status",
  "daily_short_video_time",
  "computer_os",
  "steak_preference",
  "dominant_hand",
  "enrolled_unit",
  "weekly_exercise_hours",
  "weekly_paid_work_hours",
  "assignments_on_time",
  "used_r_before",
  "team_role_type",
  "university_year",
  "favourite_anime",
  "fluent_languages",
  "readable_languages",
  "country_of_birth",
  "wam",
  "shoe_size")
 # overwrite the old names with the new names:
colnames(x) = new_names
# combine old and new into a data frame:
name_combo = bind_cols(New = new_names, Old = old_names)
```

# 2.1 Data Quality & Data Set Discussion

## Is this a random sample of DATA2X02 students?

Of the 759 students of data2x02 there were only 313 responses and hence a 41% response rate. As a majority of students did not respond there is significant room for the data set to not be a representative sample of DATA2X02 Students, or a "non-random data set". However, without conclusive descriptive statistics it is impossible to conclude. In section "what are potential biases?" we will demonstrate with a chi-squared test that this sample is not an independent sampling, implying that there is a selection bias within the data.

One way to visualize the self selection bias is through a time series of responses over time as shown below.

```{r}

daily_counts <- x |>
  group_by(timestamp) |>
  summarise(count = n())

lambda = mean(daily_counts$count)

time_series_plot <- x |>
  ggplot(aes(x = timestamp)) +
  geom_histogram(binwidth = 86400, color = "black", fill = "skyblue") + 
  labs(x = "Timestamp", y = "Frequency", title = "Frequency of Responses Over Time") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1) 
  )

time_series_plot
```

Which follows a general poisson distribution modeled by $X \sim Poisson(\lambda)$. However, there are

## What are the potential biases

Within this data set there are multiple biases, but primarily on account of the types of questions asked a response bias is present, and on account of the types of students that are inclined to respond to surveys, a selection bias is present. To determine weather a selection bias exists an additional chi-squared test for homogeneity among populations of data2902 and data2002. Under the null hypothesis the proportions of students in data2902 who responded, and data2002 who responded would be the same. This is an appropriate null hypothesis to test for independence of the two groups, as later through the report we will be analyzing traits of HD students of the sample of survey respondents.

```{r}
cols = c("respondants", "non-respondants")
rows = c("data2002", "data2902")
totals = c(675, 84)
responses = c(sum(x$enrolled_unit == "DATA2002", na.rm = TRUE), 
              sum(x$enrolled_unit == "DATA2902", na.rm = TRUE)
              )
non_responses = totals-responses
responses
mat = matrix(c(non_responses, responses), 2,2)
mat
chisq.test(mat, correct=FALSE)
chisq.test(mat, correct=FALSE)$ex #checking to see if all expected counts are greater than 5

```

Here the assumption of expected cell counts above 5 is made for the chi-squared approximation to be appropriate; a criteria that is met. Calculating the p-value with an p \>= 0.05 threshold for significance gives a p value of $2.45 \cdot 10^{-8}$; hence implying that there is a clear selection bias in the respondents of the survey. Further, this too provides a more definitive answer to "Is this a random data set of students?" â€” no, as there is a strong selection bias where data2902 students nominated themselves more frequently.

As for response bias, there are a few poorly asked questions that lead to response bias. Take for instance average hours slept. For many respondents this is a guess, often rounded to the nearest hour. Or for instance height, which in general populations approximates a normal curve.

```{r}
#as height is being used to demonstrate a point of bucketing / rounding phenomena, it is appropriate to remove inches.
x = x |> 
  dplyr::mutate(
    height_clean = readr::parse_number(height),
    height_clean = case_when(
      height_clean >= 1000 ~ NA_real_,
      height_clean <= 10 ~ NA_real_, #removing all inches
      height_clean <= 2.5 ~ height_clean*100,
      TRUE ~ height_clean
    ),
    wam_clean = case_when(
      wam >= 95 & target_grade == "HIGH_DISTINCTION" ~ NA_real_,
      wam <= 30 ~ NA_real_, #impossible to pass prerequisites with this wam
      TRUE ~ wam),

    gender_clean = case_when(
      substr(gender, 1, 1)  == "M" ~ "Male",
      substr(gender, 1, 1)  == "m" ~ "Male",
      substr(gender, 1, 1) == "F" ~ "Female",
      substr(gender, 1, 1) == "f" ~ "Female",
      TRUE ~ "Other")
  )

p1 = x |>
  ggplot()+
  aes(x = height_clean,
      fill = gender_clean) + 
  geom_histogram(binwidth = 1)+ 
  labs(x = "Height (cm)", y = "Frequency") +
  theme(
      legend.position = c(1, 1),
      legend.justification = c(1, 1),
      legend.background = element_blank(),
      legend.box.background = element_blank()
    )

p2 = x |>
  ggplot()+
  aes(x = wam_clean,
      fill = enrolled_unit
      ) + 
  geom_histogram(binwidth = 4) + 
  labs(x = "Weighted Average Mark", y = "Frequency") +
  theme(
      legend.position = c(1, 1),
      legend.justification = c(1, 1),
      legend.background = element_blank(),
      legend.box.background = element_blank()
    )

p1  + p2 + plot_layout(ncol = 2)

```

Although it could be argued that the sample in this case does represent normality somewhat accurately, there are "bin artefacts", or accumulations at the points, 160, 170, 175 and 180. This is one example of response bias where people round heights to the nearest discrete measurement. Similarly, in the plots for weighted average mark (WAM), rounding too seems to take place at 75, and around grade thresholds. The histogram of student WAM's visually conforms with an assumption of normality, however due to response bias responses tend to congregate around round grade thresholds such as distinction average (75) and credit average (65). Together this forms clear proof of response bias throught the sample in certain categories.

As a bulk of this report is concerned with performing hypothesis testing on WAM scores of students in order to understand which factors are significant and aren't significant in student academic performance, and thus data-bias in WAM scores is very important. Although the histogram of WAM scores in figure 2 does exhibit binning artefacts, it is impossible to conclude because it appears to be a bi modal distribution under DATA2902 and DATA2002 students, and likely many other factors. Nonetheless, these binning artefacts will be addressed through appropriate data-wrangling and analysis with QQ-plots to determine if chosen test statistics are appropriate if normality is assumed. However the best way to mitigate binning artefacts would be through sampling methods and question selection, which will be explored within section 2.3.

## 2.3

A

# 2.2 Specific Hypothesis Tests

## Is a linkage model between target grades and 'high', 'low' and 'medium' hours studied per week consistent with observed data at the p \< 0.05 significance level?

The purpose of investigating a linkage model between target grades (HD, D, CR, P, F) and hours studied, which was bucketed into low (0 - 15 h), medium (15 - 40h) and high ( 40+), was to see if students that expected higher grades studied more, or claimed to study more (due to survey limitations).

```{r}

x = x |> mutate(
  weekly_study_hours = as.character(weekly_study_hours),
  hours_numeric = readr::parse_number(weekly_study_hours),
  hours_numeric = case_when(
    hours_numeric > 100 ~ NA_real_,
    TRUE ~ hours_numeric
  ),
  hours_buckets = case_when(
    hours_numeric < 15 ~ "Low",
    hours_numeric > 40 ~ "High",
    TRUE ~ "Medium"
  ),
  grade = case_when(
    wam_clean < 75 ~ "CR + P", # fail students not contained in dataset
    wam_clean < 85 ~ "D",
    TRUE ~ "HD"
  )
)

table_full = table(x$hours_buckets, x$grade)
all(chisq.test(matrix(table_full, 3, 3))$ex > 5) # all values are greather than 5
chisq.test(matrix(table_full, 3, 3), p=c(1/9, 1:9))

```

1.  **Hypothesis**: $H_0: p_i=0.111, \ \text{for} \ i=1,2,...,9$ and the alternative hypothesis being $H_1:p_i\neq0.111 \ \text{for some} \ i=1,2,...,9$
2.  **Assumptions:** That all expected cell counts are above 5. An assumption that is met, after credit and pass grades are combined.
3.  **Decision:** As the p value is 0.1297, we do not reject the null hypothesis, as within the data there is sufficient evidence to suggest that there is a relationship between studying more and expecting higher grades.

HD students Expectation of grades, do HD students expect significantly different results than non HD students. Proportions of expectations ought to remain consistent through

## Are mean WAM scores significantly different between International and Domestic students at the p \< 0.05 level?

Although the survey did not explicitly ask respondents citizenship, data on residency status can be inferred from the country of birth and weekly hours worked, and living arrangment.

```{r}

x = x |> mutate(
  Citizenship = case_when(
    substr(country_of_birth, 1, 2) == "au" |
    substr(country_of_birth, 1, 2) == "AU" |
    substr(country_of_birth, 1, 2) == "Au"  ~ "Domestic",
    #add case where proof of work implies citizenship. 
    weekly_paid_work_hours >= 26 ~ "Domestic",
    TRUE ~ "International"
  ),
  # including this criteria 
  Citizenship = case_when(
    Citizenship == "International" & 
    living_arrangements == "With parent(s) and/or sibling(s)" ~ "Domestic",
    TRUE ~ Citizenship
  )
)
p1 = x |> ggplot() +
  aes(x = Citizenship, y = wam_clean, fill = Citizenship) +
  geom_violin(alpha = 0.6, color = "black") +
  geom_boxplot(width = 0.035, fill="grey", outliers = FALSE, na.rm = TRUE) +
  labs(
    title = "WAM Distribution by Citizenship Status",
    x = "Residency Status",
    y = "Weighted Average Mark (WAM)"
  ) +
  scale_fill_manual(values = c("lightblue", "aquamarine")) +
  theme_linedraw() +
  theme(plot.title = element_text(hjust = 0.5))

p2 <-  ggqqplot(x, x = 'wam_clean', facet.by = 'Citizenship') +  labs(title = "QQ-Plot: WAM by Residency")

p1 + p2 + plot_layout(ncol = 2)


```

Figure 3: Grade distributions of students enrolled in DATA2002 and DATA2902 separated by (inferred) residency status of students.

```{r}

kurtosis = function(x) {
  n <- length(x)
  mean_x <- mean(x, na.rm = TRUE)
  sd_x <- sd(x, na.rm = TRUE)
  fourth_moment <- sum((x - mean_x)^4, na.rm = TRUE) / n
  kurt <- (fourth_moment / (sd_x^4)) - 3
  return(kurt)
}
  
table_data = x |>
  select(wam_clean, Citizenship) |> 
  group_by(Citizenship) |> 
  drop_na() |>
  summarise(
    n = n(),
    Mean = mean(wam_clean) |> round(3),
    SD = sd(wam_clean) |> round(3),
    Kurtosis = kurtosis(wam_clean) |> round(3)
  )

knitr::kable(table_data)

```

1.  **Hypothesis**: Let $\mu_D$ and $\mu_I$ be average WAM scores for domestic and international students respectively. Under the null hypothesis $H_0:\mu_I=\mu_D$ vs $H_1:\mu_D>\mu_I$.

2.  **Assumptions** For two sample t-tests, there are underlying assumptions of normal distribution and equal variances. As observed within the table of variances, the standard deviations for the two samples is 9 respectively, and hence a two sample t-test is appropriate. Furthermore, as observed within the violin plots in fig 2, the distribution is symmetric (visible on the overlay box plots). Domestic students have a marginally more leptokurtic distribution than International students, but both are relatively mesokurtic. Finally, relative normality is confirmed within the QQ-plots, however the non-linear distribution of sample,theoretical z score values in the qq plot on the extreme ends should case some aspersions on the final validity of the two sample t-test. Hence, the samples of domestic and international students appear to be normally distributed.\
    \
    Finally, there is another assumption made about international and domestic students. No question was posed within the survey asking respondents about residency status, and hence this was inferred through the following criteria for being a domestic student. "1. Born in Australia or 2. live with parents or siblings or 3, work more than 26 hours per week". For the purposes of this two sample t-test, it is fair to assume that this is a fair test for domestic residency status, as the final proportions of 126 to 135 represent the approximate proportions of domestic to international students at the University of Sydney, of which DATA2X02 survey respondents are a representative sample.

3.  **Test Statistic** $$
    T = \frac{\bar{X}_D - \bar{X}_I}{\sqrt{S_p^2 \left(\frac{1}{n_D} + \frac{1}{n_I}\right)}} \\ \text{Where pooled standard deviation is given by: } S_p^2 = \frac{(n_D - 1)S_D^2 + (n_I - 1)S_I^2}{n_D + n_I - 2} \\ \text{and Degrees of freedom by: }\text{df} = n_D + n_I - 2
    $$

4.  **Observed Test Statistic:** $t0=1.617$

5.  **p-Value:** $P(t_{259} > 1.617)=0.05355$

6.  **Decision:** at the $\alpha=0.05$ significance level, do not reject the null hypothesis. Or otherwise, at the 0.05 significance level there is no reason to believe that the null hypothesis is not true within the data presented. However, given that the p value is on the threshold of 0.05, it would be wise to look further into the issue.\
    \
    Given the consequence of the alternative hypothesis being true within data, ie that domestic students score higher grades on average than international students, it would be advisable for the University and its departments to perform more extensive studies on the issue, and if the alternative hypothesis were proven true, work to resolve it by either strengthening international entry requirements, providing additional support to struggling students or look into resolving ways the ways in which students are being disadvantaged as a population. Hence more testing and data is required to achieve a conclusive result.

```{r}
#knitr::
domestic = x |>
  filter(Citizenship == "Domestic") |>
  select(wam_clean)
international = x |>
  filter(Citizenship == "International") |>
  select(wam_clean)
t.test(domestic, international, correct=FALSE, var.eq = TRUE,
       alternative="greater")

```

## Among historically HD-scoring students, there is no significant difference in anxiety levels based on the number of hours spent studying each week.

```{r}
x = x |> mutate(
  anxiety_buckets = case_when(
    daily_anxiety_frequency < 3 ~ "Low",
    daily_anxiety_frequency < 6 ~ "Moderate",
    TRUE ~ "High"
  ),
  study_buckets = case_when(
    hours_numeric < 10 ~ "0-10",
    hours_numeric < 20 ~ "10-20",
    hours_numeric < 30 ~ "20-30",
    hours_numeric < 40 ~ "30-40",
    hours_numeric < 50 ~ "40-50",
    TRUE ~ "50+"
  ),
) |> mutate(
  anxiety_buckets = factor(anxiety_buckets, levels = c("Low", "Moderate", "High")),
  study_buckets = factor(study_buckets, levels = c("0-10", "10-20", "20-30", "40-50", "50+"))
  )

hd_data = x |> filter(wam_clean >= 90)

table_full = table(hd_data$anxiety_buckets, hd_data$study_buckets)

ex = chisq.test(table_full, simulate.p.value=TRUE)$ex

high = ex[1, 1:5]
low = ex[2, 1:5]
moderate = ex[3, 1:5]
long = c(high, low, moderate)
high

length(x|>filter(grade=="HD"))

p2 = x |> filter(grade=="HD") |> filter(study_buckets != "50+") |> select(anxiety_buckets, study_buckets) |> ggplot(
  aes(
    anxiety_buckets,
  )
) +
  geom_bar(
    aes(fill=study_buckets),
    position = "dodge"
  )
p2





```

------------------------------------------------------------------------

Does a distribution of HD student expected values over hours studied and

```{r}
hd_data = x |> filter(grade == "HD") 
cr_data = x |> filter(grade == "CR + P")

table_hd = table(hd_data$anxiety_buckets, hd_data$study_buckets_fine)
chisq.test(table_hd, simulate.p.value=FALSE)$ex
chisq.test(table_hd, simulate.p.value=TRUE)$ex
?chisq.test

# Load necessary library
library(ggplot2)
library(reshape2)

# Create the data frame





```

```{r}
# Create a data frame with your proportions
data <- data.frame(
  Category = c("HD", "D", "CR", "P", "F"),
  Proportion = c(25.7, 38.5, 23.4, 10.1, 2.3)
)

# Convert proportions to fractions for the pie chart
data$Fraction <- data$Proportion / 100

# Create the pie chart
ggplot(data, aes(x = "", y = Fraction, fill = Category)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") +
  labs(title = "Proportions of Categories") +
  theme_void() +
  theme(legend.title = element_blank())
```

# ---- GRADE INFLATION

# At the 0.025 significance level, is there evidence of "grade inflation" for DATA2002 or DATA2902 students?

This Earlier this year a Sydney Morning Herald article by XXXX alleged grade inflation with data suggesting that grade distributions since 2011 had become more positive skewed in 2021. The proportions of the alleged grades are displayed below.

```{r}
smh_data = data.frame(
  Category = c("HD", "D", "CR", "P", "F"),
  proportion_2021 = c(0.257, 0.385, 0.234, 0.101, 0.023),
  proportion_2011 = c(0.077, 0.228, 0.352, 0.299, 0.044)
)

# Convert to long format

p1 = smh_data |> 
  pivot_longer(
    cols = starts_with("proportion"),
    names_to = "Year",
    values_to = "Proportion"
  ) |> 
  mutate(
    Category = factor(Category, levels = c("HD", "D", "CR", "P", "F"))
  ) |> 
  ggplot(aes(x = Category, y = Proportion, fill = Year)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("proportion_2011" = "red", "proportion_2021" = "blue")) +
  labs(title = "Proportions by Category and Year From the Sydney Morning Herald Article", x = "Category", y = "Proportion") +
  theme_minimal()

p1
```

To verify weather the students of DATA2002 are experiencing this grade inflation we will perform a chi-squared test, or a goodness of fit test, with null hypothesis being the proportions alleged in the Sydney Morning Herald Article. This test will be performed twice, once for DATA2002 and once for DATA2902.

Due to a smaller sample size, the goodness of fit test for DATA2902 has to be performed with a simulated p value, due to low expected cell counts rendering the approximation to the chi-squared distribution less accurate.

Additionally, a more stringent significance level was chosen for this test. Much of the Sydney Morning Herald article analysis outlines how grade inflation has negative societal implications and how "grade inflation could devalue degrees". Hence, hypothesis testing should reflect this additional importance, and to avoid false alarms and more stringent threshold for significance was chosen.

```{r}
set.seed(100)

x = x |> mutate (
  grade_abs = case_when(
    wam_clean < 50 ~ "F",
    wam_clean < 65 ~ "P",
    wam_clean < 75 ~ "CR",
    wam_clean < 85 ~ "D",
    TRUE ~ "HD"
  ),
)
x$grade_abs = factor(x$grade_abs, levels = c("HD", "D", "CR", "P", "F"))

x_2902 = x |> filter(enrolled_unit == "DATA2902")
x_2002 = x |> filter(enrolled_unit == "DATA2002")


chisq.test(
  table(x_2002$grade_abs), p=smh_data$proportion_2021, correct = FALSE
)

chisq.test(
  table(x_2902$grade_abs), p=smh_data$proportion_2021, simulate.p.value = TRUE, B = 10000
)

```

1.  **Hypothesis**: Under the null hypothesis, the distributions of DATA2002 and DATA2902 grades are consistent with the "grade inflated" proportions from 2021, or

    $$
    H_0: \begin{cases} p_{\text{HD}} = 0.257 \\ p_{\text{D}} = 0.385 \\ p_{\text{CR}} = 0.234 \\ p_{\text{P}} = 0.101 \\ p_{\text{F}} = 0.023 \end{cases} \\
    H_1: \text{At least one of the following is not equal to the specified proportion:} \\ \begin{cases} p_{\text{HD}} \neq 0.257 \\ p_{\text{D}} \neq 0.385 \\ p_{\text{CR}} \neq 0.234 \\ p_{\text{P}} \neq 0.101 \\ p_{\text{F}} \neq 0.023 \end{cases}
    $$

2.  **Assumptions**: For the t test performed on DATA2002, there is an assumption of expected value cell counts above 5 for all cells, which is satisfied. The assumption for DATA2902 is that there is a expected value cell count that is less than 5, making the chi-squared approximation inaccurate, which is too satisfied.

    ```{r}
    all(chisq.test(
      table(x_2002$grade_abs), p=smh_data$proportion_2021, correct = FALSE
    )$ex > 5)
    all(smh_data$proportion_2011 * sum(table(x_2902$grade_abs)) > 5) # false hence, monte carlo testing appropriate. 
    ```

3.  **Test statistic**: Test statistics for DATA2002 and DATA2902 tests respectively.

    $$
    \chi^2_{DATA2002} = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i} \\
    \chi^2_{DATA2902} = \frac{1}{B} \sum_{i=1}^{B} \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}
    $$

4.  **P value:** The $p_{2002}=0.0275$ and $p_{2902}=0.0023$

5.  **Decision**. At the 0.025 significance level, do not reject the null hypothesis for DATA2002, however do reject the DATA2902. Put in plain English, within the data there is enough evidence to say at the 0.025 significance threshold that grades do not follow the purported grade distribution of students in DATA2902 â€” implying that there is either more or less grade inflation. In DATA2002, there is not significant evidence to reject the null hypothesis, implying that at the 0.025 level there could be grade inflation in students.

    Again, this is an imperfect test due to limitations discussed in section 2.2. Additionally, this test only measures the grades of students in DATA2X02, not all subjects. Given the DATA2902 students have a minimum entry requirement of a minimum grade of 65 in DATA1001 or equivalent, it makes sense that grade inflation is even greater in DATA2902, due to a selection bias of academically inclined students picking advanced subjects.

\# ---

# How do average time spent of HD students on studying compare to non HD students.

Comparing the mean study times of students who scored a HD grade against students who did not score a HD grade.

# How does employment affect study habits of HD students

Take a subset of data where all students scored HD historically and filter for realistic submissions. How does the employment status (casual, part time, full time) of students influence hours studied.

# 3. Conclusion

Here we have showed that
